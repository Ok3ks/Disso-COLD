{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ok3ks/Disso-COLD/blob/main/Bert_20newsgroup_chunk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls4hh0XSKcer",
        "outputId": "efa32418-8556-468f-d172-9991942c2520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 95.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 77.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 73.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting fsspec[http]>=2021.11.1\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 86.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, fsspec, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.4.0 fsspec-2022.7.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers \n",
        "%pip install sklearn\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0IS6HBzs9JP"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments,DataCollatorWithPadding\n",
        "from datasets import load_dataset, load_metric,Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from utils import AssessData\n",
        "from datasets import load_dataset\n",
        "from utils import PrepareCorpus,AssessData\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset,load_dataset\n",
        "import json\n",
        "from re import template\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awi2UMSRKJGa"
      },
      "source": [
        "20 NEWSGROUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ERkFDQzYuva",
        "outputId": "4fd28f97-7310-44bd-b726-e339b4183290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcZlwCaWKJGa"
      },
      "outputs": [],
      "source": [
        "parentdir = \"/content/drive/MyDrive/ML/Datasets/20News\"\n",
        "\n",
        "train =parentdir+\"/20news-bydate\"+\"/20news-bydate-train\"\n",
        "test = parentdir+\"/20news-bydate\"+ \"/20news-bydate-test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2ac88e351e6d4f00b4bf5a1026f18918",
            "1f9a9f6f322148e4945f41ecf309c2e9",
            "c813f0a9c08d491d8142f5d5a2a563b8",
            "01216cff7df347169f86fe5aac6bc40d",
            "b41b197bf0864207ba1215f3c97337b7",
            "ec6a796b49594863839ae80de7ddf707",
            "5d383f322b5d4de482fdc2fb2aa21539",
            "3b7c1078e99c4e1b9648a22fa1595614",
            "2244c50432f54a148b8385e8efd21f40",
            "2014f24dc18d4075bba485dfa6839a73",
            "627c3cf7f97a4df09d2b4e5216fa5c10",
            "9a5bd6bb3fe7449da899a7afc1194df8",
            "476e550f9ff84866b00f5773bf563930",
            "a6bfe205450146de899e1b809db7e857",
            "680d1ae864fe470dadda04d069f06ac5",
            "a3f5d150ad1a4448be7601a0f7558cbe",
            "5419356639ea4175b2ab79adfbd9111a",
            "b5dbfd5a7f3e4fbe9ba027e230fadf7d",
            "f5efcc8ea78748deb671740d8c5e7eb4",
            "5e2559ccdb2c4e45bbb1ca2425a7a0bd",
            "8c4504ab210847efb87ae69dbe108ae4",
            "a0156ef9ab9c483b8b5e9ee60cb7a3d2",
            "a914bad5a4fa466f99fb83ab2bcb8405",
            "abd6512dce9e4a778f764688530ba99c",
            "d093f5f00ada46cfb715b1e7192ecd61",
            "f6c23f71cb194ba3b3281b8679e41720",
            "37aedfc14bae46ddb189555ffd65a4c6",
            "809b7a1e24034aa1ad26835e7a9aa06f",
            "aed38e2e26054b079b30a71750a5cc97",
            "91e4ae36d5be48c8b5b86c6cafa9a14d",
            "094783c11ecd4a1aae4eb8cbfcd3a75e",
            "e7346070be8842ab8aa50fe52d44cfa7",
            "9c747366ea814b2088d8881f30083802"
          ]
        },
        "id": "MJ72ltJt81QA",
        "outputId": "963cff59-c5d4-4e05-c92f-614453640cf7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ac88e351e6d4f00b4bf5a1026f18918"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a5bd6bb3fe7449da899a7afc1194df8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a914bad5a4fa466f99fb83ab2bcb8405"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "id2labels = {'talk.politics.mideast': 0, 'rec.autos': 1, 'comp.sys.mac.hardware': 2, 'alt.atheism': 3, 'rec.sport.baseball': 4, 'comp.os.ms-windows.misc': 5, 'rec.sport.hockey': 6, 'sci.crypt': 7, 'sci.med': 8, 'talk.politics.misc': 9, 'rec.motorcycles': 10, 'comp.windows.x': 11, 'comp.graphics': 12, 'comp.sys.ibm.pc.hardware': 13, 'sci.electronics': 14, 'talk.politics.guns': 15, 'sci.space': 16, 'soc.religion.christian': 17, 'misc.forsale': 18, 'talk.religion.misc': 19}\n",
        "id2classes = {'talk.politics.mideast': 0, 'rec.autos': 4, 'comp.sys.mac.hardware': 2, 'alt.atheism': 5, 'rec.sport.baseball': 1, 'comp.os.ms-windows.misc': 2, 'rec.sport.hockey': 1, 'sci.crypt': 3, 'sci.med': 3, 'talk.politics.misc': 0, 'rec.motorcycles': 4, 'comp.windows.x': 2, 'comp.graphics': 2, 'comp.sys.ibm.pc.hardware': 2, 'sci.electronics': 3, 'talk.politics.guns': 0, 'sci.space': 3, 'soc.religion.christian': 5, 'misc.forsale': 6, 'talk.religion.misc': 5}\n",
        "\n",
        "number = range(50,150,50)\n",
        "_per_segment = range(200,400,100)\n",
        "\n",
        "overlap = {\"side\":\"both\", \"number\": 50}\n",
        "\n",
        "f1_score = load_metric(\"f1\"); precision = load_metric(\"precision\"); recall = load_metric(\"recall\")\n",
        "\n",
        "def tokenize(batch):\n",
        "    return bert_tokenizer(batch['text'], truncation=True, max_length=max_input_length,padding = True)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, label = eval_pred\n",
        "    predictions = np.argmax(predictions, axis = 1)\n",
        "    return {\"f1\" :f1_score.compute(predictions = predictions, references = label, average = 'weighted'),\n",
        "            \"precision\" : precision.compute(predictions = predictions, references = label, average = 'weighted'),\n",
        "            \"recall\": recall.compute(predictions = predictions, references = label, average = 'weighted')}\n",
        "\n",
        "def hp_space(trial):\n",
        "  return {\"per_device_train_batch_size\": trial.suggest_discrete_uniform(\"per_device_train_batch_size\", 8,32,8)\n",
        "        ,\"learning_rate\": trial.suggest_float(\"learning_rate\", 0.00001,0.00005, log = True)\n",
        "        ,\"num_train_epochs\": trial.suggest_int(\"num_train_epochs\",1,10)}\n",
        "\n",
        "def bert_init():\n",
        "  return BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 7)\n",
        "\n",
        "def id_2_labels(x,adict):\n",
        "  \"\"\"converts labels/classes into a number using a dictionary\"\"\"\n",
        "  return adict[x]\n",
        "\n",
        "def _indexing(alist):\n",
        "  id = 0; indexed = {}\n",
        "  for x in alist:\n",
        "    for y in x:\n",
        "      id +=1\n",
        "      indexed[id] = y\n",
        "  return indexed\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP89tXq3KJGa"
      },
      "outputs": [],
      "source": [
        "news_group_train = PrepareCorpus(train)\n",
        "news_group_test = PrepareCorpus(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HVg8HU7KJGb"
      },
      "outputs": [],
      "source": [
        "news_group_test = news_group_test._prep()       #Keys are labels, values are texts\n",
        "news_group_train = news_group_train._prep()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoj9RlUgYWZX"
      },
      "source": [
        "SELECTING TWO CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sJMCTYeYhyZ"
      },
      "outputs": [],
      "source": [
        "#Selecting politics.mideast, politics.misc and sport.baseball, sport.hockey\n",
        "labels = ['talk.politics.mideast', 'talk.politics.misc', 'talk.politics.guns', 'rec.sport.baseball','rec.sport.hockey']\n",
        "\n",
        "temp_train = []; temp_test = []\n",
        "temp_news_group_train = {}; temp_news_group_test = {}\n",
        "\n",
        "for item in labels:\n",
        "  temp_news_group_train[item] = news_group_train.get(item)\n",
        "  temp_news_group_test[item] = news_group_test.get(item)\n",
        "\n",
        "temp_train = _indexing(temp_news_group_train.values())\n",
        "temp_test =  _indexing(temp_news_group_test.values())\n",
        "\n",
        "temp_train_corpus = AssessData(temp_train, temp_news_group_train)\n",
        "temp_test_corpus = AssessData(temp_test, temp_news_group_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqBQcAq7jNYn"
      },
      "outputs": [],
      "source": [
        "type(temp_train_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_XLZmXrguIc"
      },
      "outputs": [],
      "source": [
        "temp_train_index_to_label = temp_train_corpus._index_to_label() \n",
        "temp_test_index_to_label = temp_test_corpus._index_to_label()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_DyXiB2glH3"
      },
      "outputs": [],
      "source": [
        "temp_train_index_to_label = {i:id_2_labels(x,id2classes) for i,x in temp_train_index_to_label.items()}\n",
        "temp_test_index_to_label = {i:id_2_labels(x,id2classes) for i,x in temp_test_index_to_label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nIFshO8iUhj"
      },
      "outputs": [],
      "source": [
        "set(temp_train_index_to_label.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_1ZevpWioiy"
      },
      "outputs": [],
      "source": [
        "temp_train_set = temp_train_corpus._chunk(200, overlap=overlap)\n",
        "temp_train_index, temp_train_text = zip(*temp_train_set)\n",
        "\n",
        "temp_test_set = temp_test_corpus._chunk(200, overlap=overlap)\n",
        "test_index, test_text = zip(*temp_test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FJ7JVXooVOC"
      },
      "outputs": [],
      "source": [
        "frac_train_set = {\"train\" : {\"text\": temp_train.values(), 'doc_id': temp_train_index_to_label.keys(), 'labels': temp_train_index_to_label.values()}}\n",
        "frac_test_set =  {\"test\" : {\"text\": temp_test.values(), 'doc_id': temp_test_index_to_label.keys(), 'labels': temp_test_index_to_label.values()}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f1YOGZXpqA0"
      },
      "outputs": [],
      "source": [
        "frac_train_set = Dataset.from_dict(frac_train_set['train'])\n",
        "frac_test_set = Dataset.from_dict(frac_test_set['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAoEtnC0qC4g"
      },
      "outputs": [],
      "source": [
        "frac_train_set = frac_train_set.map(tokenize)\n",
        "frac_test_set = frac_test_set.map(tokenize)\n",
        "\n",
        "frac_train_set = frac_train_set.shuffle(seed = 24)\n",
        "frac_test_set = frac_test_set.shuffle(seed = 24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jojHznX5yDFd"
      },
      "outputs": [],
      "source": [
        "frac_test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6_10GUJqYNF"
      },
      "outputs": [],
      "source": [
        "fold = KFold(n_splits = 5)\n",
        "this_set = fold.split(frac_train_set['text'])\n",
        "\n",
        "frac_fold_train = []; frac_fold_eval = []\n",
        "\n",
        "for i,j in this_set:\n",
        "  frac_fold_train.append(frac_train_set.select(i))\n",
        "  frac_fold_eval.append(frac_train_set.select(j))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "TwEB6whHruAN",
        "outputId": "d545ec60-349a-48cc-b95f-dd256cabb447"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2217\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 695\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='695' max='695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [695/695 05:47, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./frac_results/checkpoint-500\n",
            "Configuration saved in ./frac_results/checkpoint-500/config.json\n",
            "Model weights saved in ./frac_results/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./frac_results/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./frac_results/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=695, training_loss=1.6512689176484566e-06, metrics={'train_runtime': 348.1553, 'train_samples_per_second': 31.839, 'train_steps_per_second': 1.996, 'total_flos': 1709213327316000.0, 'train_loss': 1.6512689176484566e-06, 'epoch': 5.0})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer, max_length= 300)\n",
        "\n",
        "#default training arguments \n",
        "training_args = TrainingArguments(output_dir=\"./frac_results\", learning_rate=2e-5, per_device_train_batch_size=16, per_device_eval_batch_size=16, num_train_epochs=5,weight_decay=0.01)\n",
        "results = []\n",
        "\n",
        "#fine-tune\n",
        "trainer = Trainer(model = bert_model, \n",
        "                args = training_args,\n",
        "                train_dataset= frac_fold_train[0],\n",
        "                eval_dataset= frac_fold_eval[0],\n",
        "                tokenizer= bert_tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics= compute_metrics)\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "s7zVcmSM0woG",
        "outputId": "cbcfa3b0-407a-4f16-f857-d4de55b264d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2217\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 695\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='695' max='695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [695/695 05:48, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.012800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./frac_results/checkpoint-500\n",
            "Configuration saved in ./frac_results/checkpoint-500/config.json\n",
            "Model weights saved in ./frac_results/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./frac_results/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./frac_results/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=695, training_loss=0.009199816647585374, metrics={'train_runtime': 349.4964, 'train_samples_per_second': 31.717, 'train_steps_per_second': 1.989, 'total_flos': 1709213327316000.0, 'train_loss': 0.009199816647585374, 'epoch': 5.0})"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_1 = Trainer(model = bert_model, \n",
        "                args = training_args,\n",
        "                train_dataset= frac_fold_train[1],\n",
        "                eval_dataset= frac_fold_eval[1],\n",
        "                tokenizer= bert_tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics= compute_metrics)\n",
        "\n",
        "trainer_1.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "Vw9NYW5j08yc",
        "outputId": "62abe147-c123-4582-df9d-2ca90cb1a5c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 555\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'f1': 1.0}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'precision': 1.0}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'recall': 1.0}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_f1': {'f1': 1.0},\n",
              " 'eval_loss': 1.2586773436851217e-06,\n",
              " 'eval_precision': {'precision': 1.0},\n",
              " 'eval_recall': {'recall': 1.0},\n",
              " 'eval_runtime': 5.8363,\n",
              " 'eval_samples_per_second': 95.095,\n",
              " 'eval_steps_per_second': 5.997}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_1.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "VfZmhSsr0_Hq",
        "outputId": "68411e2d-2cdf-4f3c-e6d8-cd82bea48d45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2218\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 695\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='695' max='695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [695/695 05:48, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./frac_results/checkpoint-500\n",
            "Configuration saved in ./frac_results/checkpoint-500/config.json\n",
            "Model weights saved in ./frac_results/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./frac_results/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./frac_results/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=695, training_loss=0.0029397173534778096, metrics={'train_runtime': 349.285, 'train_samples_per_second': 31.751, 'train_steps_per_second': 1.99, 'total_flos': 1709984285064000.0, 'train_loss': 0.0029397173534778096, 'epoch': 5.0})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_2 = Trainer(model = bert_model, \n",
        "                args = training_args,\n",
        "                train_dataset= frac_fold_train[2],\n",
        "                eval_dataset= frac_fold_eval[2],\n",
        "                tokenizer= bert_tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics= compute_metrics)\n",
        "\n",
        "trainer_2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "5AE0Bv1D1DHZ",
        "outputId": "e62de80a-b9d2-44f5-fb8d-a4ddb4022250"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 554\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'f1': 1.0}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'precision': 1.0}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'recall': 1.0}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_f1': {'f1': 1.0},\n",
              " 'eval_loss': 3.483743000742834e-07,\n",
              " 'eval_precision': {'precision': 1.0},\n",
              " 'eval_recall': {'recall': 1.0},\n",
              " 'eval_runtime': 5.8972,\n",
              " 'eval_samples_per_second': 93.943,\n",
              " 'eval_steps_per_second': 5.935}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_2.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "4zrE0axd2mb5",
        "outputId": "ce477d53-23a3-4112-b4e9-c09927808da3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2218\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 695\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='695' max='695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [695/695 05:47, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./frac_results/checkpoint-500\n",
            "Configuration saved in ./frac_results/checkpoint-500/config.json\n",
            "Model weights saved in ./frac_results/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./frac_results/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./frac_results/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=695, training_loss=0.002275791988505399, metrics={'train_runtime': 348.4291, 'train_samples_per_second': 31.829, 'train_steps_per_second': 1.995, 'total_flos': 1709984285064000.0, 'train_loss': 0.002275791988505399, 'epoch': 5.0})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_3 = Trainer(model = bert_model, \n",
        "                args = training_args,\n",
        "                train_dataset= frac_fold_train[3],\n",
        "                eval_dataset= frac_fold_eval[3],\n",
        "                tokenizer= bert_tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics= compute_metrics)\n",
        "\n",
        "trainer_3.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "UxeCRtu82qij",
        "outputId": "329ef3fe-16c7-48f2-919f-07c94312584b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 554\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'f1': 1.0}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'precision': 1.0}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'recall': 1.0}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_f1': {'f1': 1.0},\n",
              " 'eval_loss': 6.382206265698187e-07,\n",
              " 'eval_precision': {'precision': 1.0},\n",
              " 'eval_recall': {'recall': 1.0},\n",
              " 'eval_runtime': 5.8041,\n",
              " 'eval_samples_per_second': 95.449,\n",
              " 'eval_steps_per_second': 6.03}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_3.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "ka_ODeop2ugv",
        "outputId": "3bf19dc1-9a75-4cca-b7a2-99632a22bbcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2218\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 695\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='695' max='695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [695/695 05:48, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./frac_results/checkpoint-500\n",
            "Configuration saved in ./frac_results/checkpoint-500/config.json\n",
            "Model weights saved in ./frac_results/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./frac_results/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./frac_results/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=695, training_loss=0.0010128181141704027, metrics={'train_runtime': 348.5455, 'train_samples_per_second': 31.818, 'train_steps_per_second': 1.994, 'total_flos': 1709984285064000.0, 'train_loss': 0.0010128181141704027, 'epoch': 5.0})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_4 = Trainer(model = bert_model, \n",
        "                args = training_args,\n",
        "                train_dataset= frac_fold_train[3],\n",
        "                eval_dataset= frac_fold_eval[3],\n",
        "                tokenizer= bert_tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics= compute_metrics)\n",
        "\n",
        "trainer_4.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "H706tgya2xqm",
        "outputId": "91aca3a3-c4d9-4472-a74f-fc29a162fdd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 554\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'f1': 1.0}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'precision': 1.0}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'recall': 1.0}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_f1': {'f1': 1.0},\n",
              " 'eval_loss': 1.568655676464914e-07,\n",
              " 'eval_precision': {'precision': 1.0},\n",
              " 'eval_recall': {'recall': 1.0},\n",
              " 'eval_runtime': 5.8146,\n",
              " 'eval_samples_per_second': 95.278,\n",
              " 'eval_steps_per_second': 6.019}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_4.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "7rvjnMCCx0fW",
        "outputId": "3dafcdba-fa83-44f9-da30-12978404de12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: doc_id, text. If doc_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1846\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[14.098028  , -1.4912723 , -3.5197954 , ..., -3.6451075 ,\n",
              "        -3.5605521 , -3.6322472 ],\n",
              "       [14.069137  , -1.2121682 , -3.6193976 , ..., -3.7079847 ,\n",
              "        -3.6338902 , -3.6669984 ],\n",
              "       [13.988607  , -0.47171164, -3.7710178 , ..., -3.8612034 ,\n",
              "        -3.7816782 , -3.8226001 ],\n",
              "       ...,\n",
              "       [-1.0578972 , 14.913863  , -3.0020463 , ..., -3.1072378 ,\n",
              "        -3.0268278 , -3.1448991 ],\n",
              "       [-1.2890277 , 14.916755  , -2.948148  , ..., -3.0382755 ,\n",
              "        -2.986302  , -3.0952275 ],\n",
              "       [-1.289872  , 14.917773  , -2.9430904 , ..., -3.041633  ,\n",
              "        -2.9744854 , -3.0983293 ]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 1]), metrics={'test_loss': 0.11893603950738907, 'test_f1': {'f1': 0.9913352020312788}, 'test_precision': {'precision': 0.9913472673073298}, 'test_recall': {'recall': 0.991332611050921}, 'test_runtime': 19.3655, 'test_samples_per_second': 95.324, 'test_steps_per_second': 5.99})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.predict(frac_test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGIklFxpgqmI"
      },
      "source": [
        "FULL TRAIN AND TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RAA-GR6KJGb"
      },
      "outputs": [],
      "source": [
        "#Full train and test data\n",
        "\n",
        "train_list_of_strings = _indexing(news_group_train.values())\n",
        "test_list_of_strings = _indexing(news_group_test.values())\n",
        "\n",
        "train_corpus = AssessData(train_list_of_strings, news_group_train)\n",
        "test_corpus = AssessData(test_list_of_strings, news_group_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_seuBe1pkROW"
      },
      "outputs": [],
      "source": [
        "train_index_to_label = train_corpus._index_to_label() \n",
        "test_index_to_label = test_corpus._index_to_label()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv2Hwi_ODaNe"
      },
      "outputs": [],
      "source": [
        "train_index_to_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1lPqOTiQEuz",
        "outputId": "8e25a4ea-35f3-41e6-9fd9-ac779b05a3d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(set(train_index_to_label.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KNUhcFrPmLo",
        "outputId": "ca13157e-23de-47ad-84b6-312f1d9ef0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h904CxfrAxD"
      },
      "outputs": [],
      "source": [
        "train_set = train_corpus._chunk(200, overlap=overlap)\n",
        "train_index, train_text = zip(*train_set)\n",
        "\n",
        "test_set = test_corpus._chunk(200, overlap=overlap)\n",
        "test_index, test_text = zip(*test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OAeqqfQLG56"
      },
      "outputs": [],
      "source": [
        "train_index = {a:x-1 for a,x in enumerate(train_index)}\n",
        "train_text = {a:x for a,x in enumerate(train_text)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_chunked_label[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V6lsoFbUSfh",
        "outputId": "16919754-4e5d-4ccf-de50-7449b569e00f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAYhTZOzL3-Z"
      },
      "outputs": [],
      "source": [
        "test_index = {a:x-1 for a,x in enumerate(test_index)}\n",
        "test_text = {a:x for a,x in enumerate(test_text)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_-7o466livv"
      },
      "outputs": [],
      "source": [
        "train_chunked_label = {i:id_2_labels(x,train_index_to_label) for i,x in train_index.items()}\n",
        "test_chunked_label = {i:id_2_labels(x,train_index_to_label) for i,x in test_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_s4X-lwGS8z"
      },
      "outputs": [],
      "source": [
        "train_set = {\"train\" : {\"text\": train_text.values(), \"doc_id\": train_index.values(), \"labels\": train_chunked_label.values()}}\n",
        "test_set =  {\"test\" : {\"text\": test_text.values(), 'doc_id': test_index.values(), 'labels': test_chunked_label.values()}}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_index.values()), len(train_text.values()), len(train_chunked_label.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPX1BSMtcYuA",
        "outputId": "059ccd11-65f8-47fc-9584-ecf81a448419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129646, 129646, 129646)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "a = pd.DataFrame(train_set['train'])\n",
        "b = pd.DataFrame(test_set['test'])"
      ],
      "metadata": {
        "id": "FB2uzd04f_cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Nt5nWlyBoFA1",
        "outputId": "19bbb47c-a2b0-4bce-eef7-96a37340e06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  doc_id  \\\n",
              "0      From: Sang.Shin@launchpad.unc.edu (SANG SHIN)\\...       0   \n",
              "1      gy\\n Nntp-Posting-Host: lambada.oit.unc.edu\\n ...       0   \n",
              "2      ack down his post for his name)\\n was talking ...       0   \n",
              "3      h in.  Thus, each link is a possible locking p...       0   \n",
              "4      ore effective than kryptonite cable locks (IMH...       0   \n",
              "...                                                  ...     ...   \n",
              "81855  From: Patrick Pearse Gallagher <pg23+@andrew.c...    7531   \n",
              "81856   NNTP-Posting-Host: po3.andrew.cmu.edu\\n In-Re...    7531   \n",
              "81857  t injury, but since he has\\n >beenback (and be...    7531   \n",
              "81858   I beg to differ, he had a couple 3 hit games ...    7531   \n",
              "81859                                                       7531   \n",
              "\n",
              "                        labels  \n",
              "0           talk.politics.guns  \n",
              "1           talk.politics.guns  \n",
              "2           talk.politics.guns  \n",
              "3           talk.politics.guns  \n",
              "4           talk.politics.guns  \n",
              "...                        ...  \n",
              "81855  comp.os.ms-windows.misc  \n",
              "81856  comp.os.ms-windows.misc  \n",
              "81857  comp.os.ms-windows.misc  \n",
              "81858  comp.os.ms-windows.misc  \n",
              "81859  comp.os.ms-windows.misc  \n",
              "\n",
              "[81860 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b458bdc-9c83-4ba4-90a7-0187c8733f13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: Sang.Shin@launchpad.unc.edu (SANG SHIN)\\...</td>\n",
              "      <td>0</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gy\\n Nntp-Posting-Host: lambada.oit.unc.edu\\n ...</td>\n",
              "      <td>0</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ack down his post for his name)\\n was talking ...</td>\n",
              "      <td>0</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>h in.  Thus, each link is a possible locking p...</td>\n",
              "      <td>0</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ore effective than kryptonite cable locks (IMH...</td>\n",
              "      <td>0</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81855</th>\n",
              "      <td>From: Patrick Pearse Gallagher &lt;pg23+@andrew.c...</td>\n",
              "      <td>7531</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81856</th>\n",
              "      <td>NNTP-Posting-Host: po3.andrew.cmu.edu\\n In-Re...</td>\n",
              "      <td>7531</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81857</th>\n",
              "      <td>t injury, but since he has\\n &gt;beenback (and be...</td>\n",
              "      <td>7531</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81858</th>\n",
              "      <td>I beg to differ, he had a couple 3 hit games ...</td>\n",
              "      <td>7531</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81859</th>\n",
              "      <td></td>\n",
              "      <td>7531</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81860 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b458bdc-9c83-4ba4-90a7-0187c8733f13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b458bdc-9c83-4ba4-90a7-0187c8733f13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b458bdc-9c83-4ba4-90a7-0187c8733f13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Maps 20 classes to 7 classes\n",
        "\n",
        "a['labels'] = a['labels'].map(id2classes)\n",
        "b['labels'] = b['labels'].map(id2classes)"
      ],
      "metadata": {
        "id": "aWeuc4JMnZfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8yhXHSRyn4sh",
        "outputId": "7acbb845-6de1-40bb-ac55-19c32d10dc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  doc_id  labels\n",
              "0      From: Sang.Shin@launchpad.unc.edu (SANG SHIN)\\...       0       0\n",
              "1      gy\\n Nntp-Posting-Host: lambada.oit.unc.edu\\n ...       0       0\n",
              "2      ack down his post for his name)\\n was talking ...       0       0\n",
              "3      h in.  Thus, each link is a possible locking p...       0       0\n",
              "4      ore effective than kryptonite cable locks (IMH...       0       0\n",
              "...                                                  ...     ...     ...\n",
              "81855  From: Patrick Pearse Gallagher <pg23+@andrew.c...    7531       2\n",
              "81856   NNTP-Posting-Host: po3.andrew.cmu.edu\\n In-Re...    7531       2\n",
              "81857  t injury, but since he has\\n >beenback (and be...    7531       2\n",
              "81858   I beg to differ, he had a couple 3 hit games ...    7531       2\n",
              "81859                                                       7531       2\n",
              "\n",
              "[81860 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af164f46-4f72-4b5d-ac8d-7df14773e395\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: Sang.Shin@launchpad.unc.edu (SANG SHIN)\\...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gy\\n Nntp-Posting-Host: lambada.oit.unc.edu\\n ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ack down his post for his name)\\n was talking ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>h in.  Thus, each link is a possible locking p...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ore effective than kryptonite cable locks (IMH...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81855</th>\n",
              "      <td>From: Patrick Pearse Gallagher &lt;pg23+@andrew.c...</td>\n",
              "      <td>7531</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81856</th>\n",
              "      <td>NNTP-Posting-Host: po3.andrew.cmu.edu\\n In-Re...</td>\n",
              "      <td>7531</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81857</th>\n",
              "      <td>t injury, but since he has\\n &gt;beenback (and be...</td>\n",
              "      <td>7531</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81858</th>\n",
              "      <td>I beg to differ, he had a couple 3 hit games ...</td>\n",
              "      <td>7531</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81859</th>\n",
              "      <td></td>\n",
              "      <td>7531</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81860 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af164f46-4f72-4b5d-ac8d-7df14773e395')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af164f46-4f72-4b5d-ac8d-7df14773e395 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af164f46-4f72-4b5d-ac8d-7df14773e395');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modify types\n",
        "\n",
        "a['text'] = a['text'].astype(str)\n",
        "a['doc_id'] = a['doc_id'].astype(int)\n",
        "a['labels'] = a['labels'].astype(int)\n",
        "\n",
        "b['text'] = b['text'].astype(str)\n",
        "b['doc_id'] = b['doc_id'].astype(int)\n",
        "b['labels'] = b['labels'].astype(int)"
      ],
      "metadata": {
        "id": "rTy2YftCgPni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGcH1Vb3I3pJ"
      },
      "outputs": [],
      "source": [
        "train = Dataset.from_pandas(a)\n",
        "test = Dataset.from_pandas(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "157bc6894f5a4777a263f08918ea2e1f",
            "6e7f6695b362467fb4f6398c64613e7b",
            "9151bcc1fe7149be98d3a7a24c6d28f4",
            "07da8e6e817440c8914de70814c58a06",
            "3756cad448a5461aac49010587809e68",
            "b8fef181c37040e6a9368f05e077bb3e",
            "56bcfcf3c38c40e693c26573ebc46a51",
            "86cdc82dfdef4a8aa38680edf1b69403",
            "43f7415dec2a4c739f3d378c6a4222d7",
            "e5a891ed772549d9bdad05801d68707e",
            "fc034be014c6408cb07445d7d708c002"
          ]
        },
        "id": "ObjQIeKcSD3t",
        "outputId": "ee4b3fbd-7c82-4188-e271-389ca6a07f7f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/129646 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "157bc6894f5a4777a263f08918ea2e1f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "train = train.map(tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3c28f74d696d442c9c400e69c9d1b58e",
            "5e56aad4baaa41939ccdb4064283515c",
            "570d306407614af38906b1daeac7eb06",
            "6116e9a83c324c9eae33abbb1c2e84d8",
            "a41e6e62495c4146a074527b1821a770",
            "76d37f9f4a17453e97599d0f8d3d29af",
            "8da7757a622741598806d92d0cca0c81",
            "14ca8e25c50747f8892d8f4927e0b52d",
            "a6b916f16b974f279c3afd421ad946c6",
            "bd867dceee3949038be963fcd095901e",
            "6e425a01d1734e9b962a7020b3d5b9bb"
          ]
        },
        "id": "LIXXXikWSICX",
        "outputId": "179ff474-ff22-4a31-8569-18b9c6056a2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/81860 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c28f74d696d442c9c400e69c9d1b58e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "test = test.map(tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.shuffle(seed = 30)\n",
        "test = test.shuffle(seed = 30)"
      ],
      "metadata": {
        "id": "AIlNERYbdeZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97bUyeFfjY_",
        "outputId": "0e63fa7c-c505-4401-d4bb-b5960b608816"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "set(train['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UAUTI1oW9Af"
      },
      "outputs": [],
      "source": [
        "from re import template\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "fold = KFold(n_splits = 5)\n",
        "this_set = fold.split(train['text'])\n",
        "\n",
        "fold_train = []\n",
        "fold_eval = []\n",
        "\n",
        "for i,j in this_set:\n",
        "  fold_train.append(train.select(i))\n",
        "  fold_eval.append(train.select(j))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install optuna"
      ],
      "metadata": {
        "id": "uuN2CcTuke0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(output_dir=\"./results_temp\", learning_rate=2e-5, per_device_train_batch_size=32, per_device_eval_batch_size=32, num_train_epochs=5,weight_decay=0.01)\n",
        "results = []\n",
        "\n",
        "max_input_length = 300\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer, max_length= 300)\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 7)\n",
        "\n",
        "result = {}\n",
        "\n",
        "#fine-tune\n",
        "for i in range(len(fold_train)-1):\n",
        "  trainer = Trainer(model = bert_model, \n",
        "                args = training_args,\n",
        "                train_dataset= fold_train[i],\n",
        "                eval_dataset= fold_eval[i],\n",
        "                tokenizer= bert_tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics= compute_metrics)\n",
        "\n",
        "  trainer.train()\n",
        "  result[fold] = trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HyU4szYnNgQA",
        "outputId": "3d6a1c4a-ac45-4e63-da98-bfddf8176bbd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, doc_id. If text, doc_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 103716\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 16210\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16210' max='16210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16210/16210 4:32:16, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.888400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.650400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.622200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.587800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.559700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.529800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.474800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.411000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.396200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.396900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.386900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.386600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.376000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.289700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.295500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.286900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.293100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.298100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.289300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.259900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.236100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.229700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.233500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.243800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.241400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.225500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.202300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.208300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.208000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.204900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.193500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./results_temp/checkpoint-500\n",
            "Configuration saved in ./results_temp/checkpoint-500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-1000\n",
            "Configuration saved in ./results_temp/checkpoint-1000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-1000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-1500\n",
            "Configuration saved in ./results_temp/checkpoint-1500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-1500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-2000\n",
            "Configuration saved in ./results_temp/checkpoint-2000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-2000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-2500\n",
            "Configuration saved in ./results_temp/checkpoint-2500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-2500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-3000\n",
            "Configuration saved in ./results_temp/checkpoint-3000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-3000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-3500\n",
            "Configuration saved in ./results_temp/checkpoint-3500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-3500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-4000\n",
            "Configuration saved in ./results_temp/checkpoint-4000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-4000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-4500\n",
            "Configuration saved in ./results_temp/checkpoint-4500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-4500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-5000\n",
            "Configuration saved in ./results_temp/checkpoint-5000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-5000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-5500\n",
            "Configuration saved in ./results_temp/checkpoint-5500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-5500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-6000\n",
            "Configuration saved in ./results_temp/checkpoint-6000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-6000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-6500\n",
            "Configuration saved in ./results_temp/checkpoint-6500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-6500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-7000\n",
            "Configuration saved in ./results_temp/checkpoint-7000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-7000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-7500\n",
            "Configuration saved in ./results_temp/checkpoint-7500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-7500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-8000\n",
            "Configuration saved in ./results_temp/checkpoint-8000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-8000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-8500\n",
            "Configuration saved in ./results_temp/checkpoint-8500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-8500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-9000\n",
            "Configuration saved in ./results_temp/checkpoint-9000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-9000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-9500\n",
            "Configuration saved in ./results_temp/checkpoint-9500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-9500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-10000\n",
            "Configuration saved in ./results_temp/checkpoint-10000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-10000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-10500\n",
            "Configuration saved in ./results_temp/checkpoint-10500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-10500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-11000\n",
            "Configuration saved in ./results_temp/checkpoint-11000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-11000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-11500\n",
            "Configuration saved in ./results_temp/checkpoint-11500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-11500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-12000\n",
            "Configuration saved in ./results_temp/checkpoint-12000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-12000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-12500\n",
            "Configuration saved in ./results_temp/checkpoint-12500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-12500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-13000\n",
            "Configuration saved in ./results_temp/checkpoint-13000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-13000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-13500\n",
            "Configuration saved in ./results_temp/checkpoint-13500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-13500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-14000\n",
            "Configuration saved in ./results_temp/checkpoint-14000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-14000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-14500\n",
            "Configuration saved in ./results_temp/checkpoint-14500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-14500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-15000\n",
            "Configuration saved in ./results_temp/checkpoint-15000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-15000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-15500\n",
            "Configuration saved in ./results_temp/checkpoint-15500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-15500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-15500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-15500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-16000\n",
            "Configuration saved in ./results_temp/checkpoint-16000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-16000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-16000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-16000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, doc_id. If text, doc_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 25930\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='811' max='811' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [811/811 04:55]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'f1': 0.8569251717504416}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'precision': 0.8679177558339705}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'recall': 0.8557269571924412}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, doc_id. If text, doc_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 103717\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 16210\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16210' max='16210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16210/16210 4:32:08, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.316800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.308600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.317500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.298600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.315700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.297500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.241100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.239200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.242400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.236000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.237100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.237100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.202200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.209400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.199100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.201200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.212800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.210900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.199300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.181600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.175200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.185900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.185300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.196500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.178300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.172200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.179800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.174000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.172700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.177200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.169200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./results_temp/checkpoint-500\n",
            "Configuration saved in ./results_temp/checkpoint-500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-1000\n",
            "Configuration saved in ./results_temp/checkpoint-1000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-1000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-1500\n",
            "Configuration saved in ./results_temp/checkpoint-1500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-1500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-2000\n",
            "Configuration saved in ./results_temp/checkpoint-2000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-2000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-2500\n",
            "Configuration saved in ./results_temp/checkpoint-2500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-2500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-3000\n",
            "Configuration saved in ./results_temp/checkpoint-3000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-3000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-3500\n",
            "Configuration saved in ./results_temp/checkpoint-3500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-3500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-4000\n",
            "Configuration saved in ./results_temp/checkpoint-4000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-4000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-4500\n",
            "Configuration saved in ./results_temp/checkpoint-4500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-4500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-5000\n",
            "Configuration saved in ./results_temp/checkpoint-5000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-5000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-5500\n",
            "Configuration saved in ./results_temp/checkpoint-5500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-5500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-6000\n",
            "Configuration saved in ./results_temp/checkpoint-6000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-6000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-6500\n",
            "Configuration saved in ./results_temp/checkpoint-6500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-6500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-7000\n",
            "Configuration saved in ./results_temp/checkpoint-7000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-7000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-7500\n",
            "Configuration saved in ./results_temp/checkpoint-7500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-7500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-8000\n",
            "Configuration saved in ./results_temp/checkpoint-8000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-8000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-8500\n",
            "Configuration saved in ./results_temp/checkpoint-8500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-8500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-9000\n",
            "Configuration saved in ./results_temp/checkpoint-9000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-9000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-9500\n",
            "Configuration saved in ./results_temp/checkpoint-9500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-9500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-10000\n",
            "Configuration saved in ./results_temp/checkpoint-10000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-10000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-10500\n",
            "Configuration saved in ./results_temp/checkpoint-10500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-10500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-11000\n",
            "Configuration saved in ./results_temp/checkpoint-11000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-11000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-11500\n",
            "Configuration saved in ./results_temp/checkpoint-11500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-11500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-12000\n",
            "Configuration saved in ./results_temp/checkpoint-12000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-12000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-12500\n",
            "Configuration saved in ./results_temp/checkpoint-12500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-12500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-13000\n",
            "Configuration saved in ./results_temp/checkpoint-13000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-13000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-13500\n",
            "Configuration saved in ./results_temp/checkpoint-13500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-13500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-14000\n",
            "Configuration saved in ./results_temp/checkpoint-14000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-14000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-14500\n",
            "Configuration saved in ./results_temp/checkpoint-14500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-14500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-15000\n",
            "Configuration saved in ./results_temp/checkpoint-15000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-15000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-15500\n",
            "Configuration saved in ./results_temp/checkpoint-15500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-15500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-15500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-15500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-16000\n",
            "Configuration saved in ./results_temp/checkpoint-16000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-16000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-16000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-16000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, doc_id. If text, doc_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 25929\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='811' max='811' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [811/811 05:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"{'f1': 0.9222658494959324}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'precision': 0.9341079895250561}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'recall': 0.9200894751050946}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, doc_id. If text, doc_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 103717\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 16210\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='622' max='16210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  622/16210 10:26 < 4:22:21, 0.99 it/s, Epoch 0.19/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.222100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./results_temp/checkpoint-500\n",
            "Configuration saved in ./results_temp/checkpoint-500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16210' max='16210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16210/16210 4:32:59, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.222100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.224600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.225300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.233800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.224000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.209900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.202500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.196000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.208300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.194200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.203100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.204200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.181100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.183300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.181000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.182500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.189900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.194100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.189100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.167800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.171400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.172000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.177500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.183900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.172300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.170900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.166700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.173500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.176600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.162800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results_temp/checkpoint-1000\n",
            "Configuration saved in ./results_temp/checkpoint-1000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-1000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-1500\n",
            "Configuration saved in ./results_temp/checkpoint-1500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-1500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-2000\n",
            "Configuration saved in ./results_temp/checkpoint-2000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-2000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-2500\n",
            "Configuration saved in ./results_temp/checkpoint-2500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-2500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-3000\n",
            "Configuration saved in ./results_temp/checkpoint-3000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-3000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-3500\n",
            "Configuration saved in ./results_temp/checkpoint-3500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-3500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-4000\n",
            "Configuration saved in ./results_temp/checkpoint-4000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-4000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-4500\n",
            "Configuration saved in ./results_temp/checkpoint-4500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-4500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-5000\n",
            "Configuration saved in ./results_temp/checkpoint-5000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-5000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-5500\n",
            "Configuration saved in ./results_temp/checkpoint-5500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-5500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-6000\n",
            "Configuration saved in ./results_temp/checkpoint-6000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-6000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-6500\n",
            "Configuration saved in ./results_temp/checkpoint-6500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-6500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-7000\n",
            "Configuration saved in ./results_temp/checkpoint-7000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-7000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-7500\n",
            "Configuration saved in ./results_temp/checkpoint-7500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-7500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-8000\n",
            "Configuration saved in ./results_temp/checkpoint-8000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-8000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-8500\n",
            "Configuration saved in ./results_temp/checkpoint-8500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-8500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-9000\n",
            "Configuration saved in ./results_temp/checkpoint-9000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-9000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-9500\n",
            "Configuration saved in ./results_temp/checkpoint-9500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-9500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-10000\n",
            "Configuration saved in ./results_temp/checkpoint-10000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-10000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-10500\n",
            "Configuration saved in ./results_temp/checkpoint-10500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-10500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-11000\n",
            "Configuration saved in ./results_temp/checkpoint-11000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-11000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-11500\n",
            "Configuration saved in ./results_temp/checkpoint-11500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-11500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-12000\n",
            "Configuration saved in ./results_temp/checkpoint-12000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-12000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-12500\n",
            "Configuration saved in ./results_temp/checkpoint-12500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-12500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-13000\n",
            "Configuration saved in ./results_temp/checkpoint-13000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-13000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-13500\n",
            "Configuration saved in ./results_temp/checkpoint-13500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-13500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-14000\n",
            "Configuration saved in ./results_temp/checkpoint-14000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-14000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-14500\n",
            "Configuration saved in ./results_temp/checkpoint-14500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-14500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-15000\n",
            "Configuration saved in ./results_temp/checkpoint-15000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-15000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-15500\n",
            "Configuration saved in ./results_temp/checkpoint-15500/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-15500/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-15500/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-15500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "Saving model checkpoint to ./results_temp/checkpoint-16000\n",
            "Configuration saved in ./results_temp/checkpoint-16000/config.json\n",
            "Model weights saved in ./results_temp/checkpoint-16000/pytorch_model.bin\n",
            "tokenizer config file saved in ./results_temp/checkpoint-16000/tokenizer_config.json\n",
            "Special tokens file saved in ./results_temp/checkpoint-16000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, doc_id. If text, doc_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 25929\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='811' max='811' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [811/811 05:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"{'f1': 0.934695986240775}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'precision': 0.9457526149958522}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'recall': 0.9325851363338347}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, doc_id. If text, doc_id are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 103717\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 16210\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='362' max='16210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  362/16210 06:00 < 4:24:29, 1.00 it/s, Epoch 0.11/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-9f4083ba597c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                 compute_metrics= compute_metrics)\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         )\n\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2486\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2488\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTN7xEezNuf9",
        "outputId": "8ffa3afd-fcb8-4570-d897-e5585cdcf49c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{KFold(n_splits=5, random_state=None, shuffle=False): {'epoch': 5.0,\n",
              "  'eval_f1': {'f1': 0.934695986240775},\n",
              "  'eval_loss': 0.17530567944049835,\n",
              "  'eval_precision': {'precision': 0.9457526149958522},\n",
              "  'eval_recall': {'recall': 0.9325851363338347},\n",
              "  'eval_runtime': 301.1003,\n",
              "  'eval_samples_per_second': 86.114,\n",
              "  'eval_steps_per_second': 2.693}}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"7_classes.json\", \"w\") as ins:\n",
        "  json.dump(result, ins)"
      ],
      "metadata": {
        "id": "ikp5XEyO4Dxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfSYx11e3LyK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open (\"eval_32_32\", \"w\") as out: \n",
        "  json.dump(eval_32_32, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XQZarrBKJGb"
      },
      "source": [
        "IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0aMzvJiKJGc",
        "outputId": "d224203f-3184-487b-e1d7-246b9571eb77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset imdb (/Users/max/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
            "100%|██████████| 3/3 [00:00<00:00, 516.69it/s]\n"
          ]
        }
      ],
      "source": [
        "imdb = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk8kL33AKJGc"
      },
      "outputs": [],
      "source": [
        "train_imdb = imdb['train']\n",
        "test_imdb = imdb['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDjyZfsTKJGc"
      },
      "outputs": [],
      "source": [
        "train_imdb_assess = AssessData(train_imdb['text'])\n",
        "test_imdb_assess = AssessData(test_imdb['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQI9GoI3KJGc",
        "outputId": "c971ff57-fdb0-4fa3-9bd8-d3334957c495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Too Long': 0, 'Long': 3012, 'BERT': 4759, 'Short': 17229}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Too Long': 0, 'Long': 2803, 'BERT': 4639, 'Short': 17558}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_imdb_assess._create_distribution()\n",
        "train_imdb_assess._visualise()\n",
        "\n",
        "test_imdb_assess._create_distribution()\n",
        "test_imdb_assess._visualise()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irCJM03TKJGc"
      },
      "outputs": [],
      "source": [
        "#Use cross_validation on test_data to tune model parameters"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Bert_20newsgroup_chunk.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 ('proj_env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "00fa038ed48c4eea42567d095517abf695de8aa7e1762e670247e78bfd9e4117"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ac88e351e6d4f00b4bf5a1026f18918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f9a9f6f322148e4945f41ecf309c2e9",
              "IPY_MODEL_c813f0a9c08d491d8142f5d5a2a563b8",
              "IPY_MODEL_01216cff7df347169f86fe5aac6bc40d"
            ],
            "layout": "IPY_MODEL_b41b197bf0864207ba1215f3c97337b7"
          }
        },
        "1f9a9f6f322148e4945f41ecf309c2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec6a796b49594863839ae80de7ddf707",
            "placeholder": "​",
            "style": "IPY_MODEL_5d383f322b5d4de482fdc2fb2aa21539",
            "value": "Downloading builder script: "
          }
        },
        "c813f0a9c08d491d8142f5d5a2a563b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7c1078e99c4e1b9648a22fa1595614",
            "max": 2318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2244c50432f54a148b8385e8efd21f40",
            "value": 2318
          }
        },
        "01216cff7df347169f86fe5aac6bc40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2014f24dc18d4075bba485dfa6839a73",
            "placeholder": "​",
            "style": "IPY_MODEL_627c3cf7f97a4df09d2b4e5216fa5c10",
            "value": " 6.50k/? [00:00&lt;00:00, 227kB/s]"
          }
        },
        "b41b197bf0864207ba1215f3c97337b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6a796b49594863839ae80de7ddf707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d383f322b5d4de482fdc2fb2aa21539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b7c1078e99c4e1b9648a22fa1595614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2244c50432f54a148b8385e8efd21f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2014f24dc18d4075bba485dfa6839a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627c3cf7f97a4df09d2b4e5216fa5c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a5bd6bb3fe7449da899a7afc1194df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_476e550f9ff84866b00f5773bf563930",
              "IPY_MODEL_a6bfe205450146de899e1b809db7e857",
              "IPY_MODEL_680d1ae864fe470dadda04d069f06ac5"
            ],
            "layout": "IPY_MODEL_a3f5d150ad1a4448be7601a0f7558cbe"
          }
        },
        "476e550f9ff84866b00f5773bf563930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5419356639ea4175b2ab79adfbd9111a",
            "placeholder": "​",
            "style": "IPY_MODEL_b5dbfd5a7f3e4fbe9ba027e230fadf7d",
            "value": "Downloading builder script: "
          }
        },
        "a6bfe205450146de899e1b809db7e857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5efcc8ea78748deb671740d8c5e7eb4",
            "max": 2575,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e2559ccdb2c4e45bbb1ca2425a7a0bd",
            "value": 2575
          }
        },
        "680d1ae864fe470dadda04d069f06ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c4504ab210847efb87ae69dbe108ae4",
            "placeholder": "​",
            "style": "IPY_MODEL_a0156ef9ab9c483b8b5e9ee60cb7a3d2",
            "value": " 7.55k/? [00:00&lt;00:00, 300kB/s]"
          }
        },
        "a3f5d150ad1a4448be7601a0f7558cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5419356639ea4175b2ab79adfbd9111a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5dbfd5a7f3e4fbe9ba027e230fadf7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5efcc8ea78748deb671740d8c5e7eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e2559ccdb2c4e45bbb1ca2425a7a0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c4504ab210847efb87ae69dbe108ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0156ef9ab9c483b8b5e9ee60cb7a3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a914bad5a4fa466f99fb83ab2bcb8405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abd6512dce9e4a778f764688530ba99c",
              "IPY_MODEL_d093f5f00ada46cfb715b1e7192ecd61",
              "IPY_MODEL_f6c23f71cb194ba3b3281b8679e41720"
            ],
            "layout": "IPY_MODEL_37aedfc14bae46ddb189555ffd65a4c6"
          }
        },
        "abd6512dce9e4a778f764688530ba99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_809b7a1e24034aa1ad26835e7a9aa06f",
            "placeholder": "​",
            "style": "IPY_MODEL_aed38e2e26054b079b30a71750a5cc97",
            "value": "Downloading builder script: "
          }
        },
        "d093f5f00ada46cfb715b1e7192ecd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e4ae36d5be48c8b5b86c6cafa9a14d",
            "max": 2524,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_094783c11ecd4a1aae4eb8cbfcd3a75e",
            "value": 2524
          }
        },
        "f6c23f71cb194ba3b3281b8679e41720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7346070be8842ab8aa50fe52d44cfa7",
            "placeholder": "​",
            "style": "IPY_MODEL_9c747366ea814b2088d8881f30083802",
            "value": " 7.38k/? [00:00&lt;00:00, 283kB/s]"
          }
        },
        "37aedfc14bae46ddb189555ffd65a4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "809b7a1e24034aa1ad26835e7a9aa06f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed38e2e26054b079b30a71750a5cc97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e4ae36d5be48c8b5b86c6cafa9a14d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094783c11ecd4a1aae4eb8cbfcd3a75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7346070be8842ab8aa50fe52d44cfa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c747366ea814b2088d8881f30083802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "157bc6894f5a4777a263f08918ea2e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e7f6695b362467fb4f6398c64613e7b",
              "IPY_MODEL_9151bcc1fe7149be98d3a7a24c6d28f4",
              "IPY_MODEL_07da8e6e817440c8914de70814c58a06"
            ],
            "layout": "IPY_MODEL_3756cad448a5461aac49010587809e68"
          }
        },
        "6e7f6695b362467fb4f6398c64613e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8fef181c37040e6a9368f05e077bb3e",
            "placeholder": "​",
            "style": "IPY_MODEL_56bcfcf3c38c40e693c26573ebc46a51",
            "value": "100%"
          }
        },
        "9151bcc1fe7149be98d3a7a24c6d28f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86cdc82dfdef4a8aa38680edf1b69403",
            "max": 129646,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43f7415dec2a4c739f3d378c6a4222d7",
            "value": 129646
          }
        },
        "07da8e6e817440c8914de70814c58a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a891ed772549d9bdad05801d68707e",
            "placeholder": "​",
            "style": "IPY_MODEL_fc034be014c6408cb07445d7d708c002",
            "value": " 129646/129646 [02:49&lt;00:00, 817.40ex/s]"
          }
        },
        "3756cad448a5461aac49010587809e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8fef181c37040e6a9368f05e077bb3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56bcfcf3c38c40e693c26573ebc46a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86cdc82dfdef4a8aa38680edf1b69403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43f7415dec2a4c739f3d378c6a4222d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5a891ed772549d9bdad05801d68707e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc034be014c6408cb07445d7d708c002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c28f74d696d442c9c400e69c9d1b58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e56aad4baaa41939ccdb4064283515c",
              "IPY_MODEL_570d306407614af38906b1daeac7eb06",
              "IPY_MODEL_6116e9a83c324c9eae33abbb1c2e84d8"
            ],
            "layout": "IPY_MODEL_a41e6e62495c4146a074527b1821a770"
          }
        },
        "5e56aad4baaa41939ccdb4064283515c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d37f9f4a17453e97599d0f8d3d29af",
            "placeholder": "​",
            "style": "IPY_MODEL_8da7757a622741598806d92d0cca0c81",
            "value": "100%"
          }
        },
        "570d306407614af38906b1daeac7eb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ca8e25c50747f8892d8f4927e0b52d",
            "max": 81860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6b916f16b974f279c3afd421ad946c6",
            "value": 81860
          }
        },
        "6116e9a83c324c9eae33abbb1c2e84d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd867dceee3949038be963fcd095901e",
            "placeholder": "​",
            "style": "IPY_MODEL_6e425a01d1734e9b962a7020b3d5b9bb",
            "value": " 81860/81860 [01:52&lt;00:00, 822.15ex/s]"
          }
        },
        "a41e6e62495c4146a074527b1821a770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d37f9f4a17453e97599d0f8d3d29af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da7757a622741598806d92d0cca0c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14ca8e25c50747f8892d8f4927e0b52d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b916f16b974f279c3afd421ad946c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd867dceee3949038be963fcd095901e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e425a01d1734e9b962a7020b3d5b9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}