{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "#from sklearn.datasets import fetch_20newsgroups #encountered issues SSLCertificationError with this \n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods\n",
    "\n",
    "def parse_html(text):\n",
    "    \"removes hyperlink from a piece of text\"\n",
    "    \n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    parsed_text = soup.get_text()\n",
    "    return parsed_text\n",
    "\n",
    "\n",
    "def preproc(text):\n",
    "\n",
    "    refined_text = re.sub(\"(\\n)\", \" \", text) #removes python newline \n",
    "    refined_text = re.sub(\"\\w+(\\')\", \"\" , refined_text) #removes backslash\n",
    "    refined_text = re.sub(\"(\\s+)\", \" \", refined_text) #removes whitespaces\n",
    "    refined_text = re.sub(\"(&amp|>+|-+)\", \" \", refined_text)\n",
    "    refined_text = re.sub(\"(\\d+)\", \"\", refined_text) #removes digits\n",
    "    refined_text = re.sub(\"\\W*(@)\", \"\", refined_text) #removes emails \n",
    "\n",
    "    #refined_text = re.sub(\"[>|<-\\\\\", \" \", )\n",
    "\n",
    "    return refined_text\n",
    "\n",
    "def prepare_corpus(path):\n",
    "    \"\"\"BY date\"\"\"\n",
    "    corpus = []; temp = []\n",
    "    for topic in os.listdir(path):\n",
    "        subfolder = path + '/' + topic\n",
    "        for doc in os.listdir(subfolder):\n",
    "            file = subfolder + '/' + doc\n",
    "            with open(file, 'r', encoding='utf-8', errors= 'ignore') as t:\n",
    "                corpus.append((preproc(\" \".join(t.readlines())),topic),)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def preproc_newsgroup(text):\n",
    "\n",
    "    refined_text = re.sub(\"(\\n)\", \" \", text)\n",
    "    refined_text = re.sub(\"(\\s+)\", \" \", refined_text)\n",
    "    refined_text = re.sub(\"(&amp)\", \" \", refined_text)\n",
    "\n",
    "    return\n",
    "\n",
    "def check_length(text):\n",
    "    return\n",
    "\n",
    "def extra_long_documents(text):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hyperpartisan_news_detection (/Users/max/.cache/huggingface/datasets/hyperpartisan_news_detection/byarticle/1.0.0/7f4215b0474950ddf516e806400ab81d098b3da3b3a919a13cd1a4cf2c677012)\n",
      "100%|██████████| 1/1 [00:00<00:00, 590.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperpartisan_dataset = load_dataset(\"hyperpartisan_news_detection\", \"byarticle\") #Not stripped of headers and footers\n",
    "hyperpartisan_dataset.keys()\n",
    "\n",
    "#change to bypublisher because byarticle has no test set.\n",
    "article_df = pd.DataFrame(hyperpartisan_dataset['train'])\n",
    "#article_test_df = pd.DataFrame(hyperpartisan_dataset['test'])\n",
    "\n",
    "article_text = []\n",
    "\n",
    "#\n",
    "train_text_list = list(article_df['text'])\n",
    "train_tags_list = list(article_df['hyperpartisan'])\n",
    "train_article_title = list(article_df['title'])\n",
    "\n",
    "#\n",
    "#test_text_list = list(article_test_df['text'])\n",
    "#test_tags_list = list(article_test_df['hyperpartisan'])\n",
    "#test_article_title = list(article_test_df['title'])\n",
    "\n",
    "for item in train_text_list:\n",
    "    article_text.append(preproc(parse_html(item)))\n",
    "    \n",
    "len(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 7532)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroup_path = \"20news-bydate\"\n",
    "element = os.listdir(newsgroup_path)\n",
    "\n",
    "newsgroup_train_path = newsgroup_path + '/' + element[1]\n",
    "newsgroup_test_path = newsgroup_path + '/' + element[0]\n",
    "\n",
    "newsgroup_train = prepare_corpus(newsgroup_train_path)\n",
    "newsgroup_test = prepare_corpus(newsgroup_test_path)\n",
    "\n",
    "len(newsgroup_train), newsgroup_train[0], newsgroup_train[0][0]\n",
    "\n",
    "X_train_newsgroup_text, y_label = zip(*newsgroup_train)\n",
    "X_test_newsgroup_text, y_label = zip(*newsgroup_test)\n",
    "\n",
    "len(X_train_newsgroup_text),len(X_test_newsgroup_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelled the conversation with a bag of words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: perrydsinc.com (Jim Perry) Subject: Re: [soc.motss, et al.] \"Princeton axes matching funds for Boy Scouts\" Article I.D.: dsi.pqskINNhi Distribution: usa Organization: Decision Support Inc. Lines:  NNTP Posting Host: dsi.dsinc.com In article <Aprmidway.uchicago.edu  shoumidway.uchicago.edu writes:  In article <pidhINNubdsi.dsinc.com  perrydsinc.com (Jim Perry) writes:  Bigots never concede that their bigotry is irrational; it  is other people who determine that by examining their arguments.  [...]  No! I expected it! ve set yourself up a wonderful little  world where a bigot is whomever you say it is. This is very  comfortable for you imagine, never having to entertain an  argument against your belief system. Simply accuse the person  making of being a bigot. Well, this particular thread of vituperation slopped its venom over into alt.atheism, where we spend most of our time entertaining arguments against our belief system, without resorting to accusing others of bigotry. s somewhat ironic that our exposure to bigotry happens in this instance to have originated in rec.scouting, since I always understood scouting to teach tolerance and diversity. I understand bigotry to be irrational prejudice against other people who happen to be of a different race, religion, ethnic background, sex, or other inconsequential characteristics. All the evidence ve seen indicates that sexual orientation and lack of belief in gods are exactly such inconsequential characteristics. Thus, pending further evidence, I conclude that those who show prejudice against such people are bigots, and organizations that exclude such people are discriminatory.   Jim Perry perrydsinc.com Decision Support, Inc., Matthews NC These are my opinions. For a nominal fee, they can be yours. '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_newsgroup_text[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 105178)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/Desktop/Dissertation/implementations/Disso-COLD/proj_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem import PorterStemmer\n",
    "\n",
    "#lemmatize = WordNetLemmatizer()\n",
    "#stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def extract_features(text, method = \"Tfidf\"):\n",
    "    \"\"\"Count represents the number of features to be chosen from tfidf while text represents text data\n",
    "    vectorizer is either count_vectorizer or tfidfvectorizer\"\"\"\n",
    "    \n",
    "    if method == \"Tfidf\":\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    elif method == \"Count\":\n",
    "        vectorizer = CountVectorizer()\n",
    "    else:\n",
    "        print(\"wrong method\")\n",
    "\n",
    "    vec = vectorizer.fit_transform(text)\n",
    "    X_features = vectorizer.get_feature_names()\n",
    "    print(vec.shape)\n",
    "    return vec, X_features\n",
    "\n",
    "vec, feat = extract_features(X_train_newsgroup_text, \"Count\")\n",
    "\n",
    "#Filter features to have consistent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__',\n",
       " '___',\n",
       " '____',\n",
       " '_____',\n",
       " '______',\n",
       " '_______',\n",
       " '________',\n",
       " '_________',\n",
       " '__________',\n",
       " '_____________',\n",
       " '_______________',\n",
       " '________________',\n",
       " '_________________',\n",
       " '___________________',\n",
       " '_____________________',\n",
       " '________________________',\n",
       " '___________________________',\n",
       " '________________________________',\n",
       " '___________________________________',\n",
       " '_____________________________________________',\n",
       " '______________________________________________',\n",
       " '________________________________________________________',\n",
       " '__________________________________________________________',\n",
       " '_______________________________________________________________',\n",
       " '________________________________________________________________',\n",
       " '_________________________________________________________________',\n",
       " '___________________________________________________________________',\n",
       " '____________________________________________________________________',\n",
       " '______________________________________________________________________',\n",
       " '________________________________________________________________________',\n",
       " '_________________________________________________________________________',\n",
       " '__________________________________________________________________________',\n",
       " '___________________________________________________________________________',\n",
       " '______________________________________________________________________________',\n",
       " '_______________________________________________________________________________',\n",
       " '______________________nnnnn______',\n",
       " '___________________the',\n",
       " '_________pratice',\n",
       " '______nnnnn______________________',\n",
       " '_____u_____',\n",
       " '____i__i__',\n",
       " '___i__',\n",
       " '___i__ii',\n",
       " '___samuel___',\n",
       " '__dave',\n",
       " '__l__',\n",
       " '__livian__',\n",
       " '__o',\n",
       " '__questionnaire__',\n",
       " '__segal__',\n",
       " '__v__',\n",
       " '_a',\n",
       " '_alone_',\n",
       " '_also_',\n",
       " '_any_',\n",
       " '_anything_',\n",
       " '_are_',\n",
       " '_as',\n",
       " '_assumption_',\n",
       " '_atheism',\n",
       " '_bad_',\n",
       " '_barfly_',\n",
       " '_because_',\n",
       " '_before_',\n",
       " '_behaviors_',\n",
       " '_being_',\n",
       " '_believe_',\n",
       " '_bensonfourd',\n",
       " '_claims_',\n",
       " '_congressional',\n",
       " '_covenant_',\n",
       " '_deadly',\n",
       " '_decision_',\n",
       " '_decreases_',\n",
       " '_defined_',\n",
       " '_definitely_',\n",
       " '_did_',\n",
       " '_do_',\n",
       " '_does_',\n",
       " '_edge_',\n",
       " '_empire_',\n",
       " '_emt',\n",
       " '_enforcement_',\n",
       " '_erik',\n",
       " '_everything',\n",
       " '_evidence_',\n",
       " '_except_',\n",
       " '_faster_',\n",
       " '_floor',\n",
       " '_for',\n",
       " '_have_',\n",
       " '_heard_',\n",
       " '_him_',\n",
       " '_hood_',\n",
       " '_i_',\n",
       " '_if_',\n",
       " '_impending',\n",
       " '_in',\n",
       " '_includes_',\n",
       " '_including_',\n",
       " '_incredibly_',\n",
       " '_internal_',\n",
       " '_international',\n",
       " '_is_',\n",
       " '_kampmanbmug',\n",
       " '_killed_',\n",
       " '_know_',\n",
       " '_knowledgeable',\n",
       " '_krebsmcontent',\n",
       " '_little_',\n",
       " '_lots_',\n",
       " '_love_',\n",
       " '_macweek_',\n",
       " '_may_',\n",
       " '_memoirs',\n",
       " '_millions_',\n",
       " '_mine_',\n",
       " '_model_',\n",
       " '_much_',\n",
       " '_mullendbug',\n",
       " '_must_',\n",
       " '_myths',\n",
       " '_national',\n",
       " '_necessarily_',\n",
       " '_never_',\n",
       " '_new',\n",
       " '_not_',\n",
       " '_o_',\n",
       " '_one',\n",
       " '_opposite_',\n",
       " '_our_',\n",
       " '_over',\n",
       " '_oxygen',\n",
       " '_palestinian',\n",
       " '_personal_',\n",
       " '_pink_unicorns_',\n",
       " '_positive_',\n",
       " '_precise_',\n",
       " '_prima',\n",
       " '_private_',\n",
       " '_quantum_',\n",
       " '_real_',\n",
       " '_really_',\n",
       " '_reject_',\n",
       " '_rejects_',\n",
       " '_religion_',\n",
       " '_requirements_',\n",
       " '_rv',\n",
       " '_schniderbmug',\n",
       " '_se_',\n",
       " '_search_',\n",
       " '_secret_',\n",
       " '_service',\n",
       " '_should_',\n",
       " '_simple',\n",
       " '_some_',\n",
       " '_somewhere_',\n",
       " '_sons_',\n",
       " '_still_',\n",
       " '_talk_',\n",
       " '_that_',\n",
       " '_the',\n",
       " '_the_',\n",
       " '_the_users_guide_to_invisible_',\n",
       " '_the_wholly_babble',\n",
       " '_their_',\n",
       " '_think_',\n",
       " '_tsv_',\n",
       " '_very',\n",
       " '_very_',\n",
       " '_vvklrpi',\n",
       " '_want_',\n",
       " '_wardbmug',\n",
       " '_waving',\n",
       " '_we_',\n",
       " '_which',\n",
       " '_wilsonmcontent',\n",
       " '_with_',\n",
       " '_would_',\n",
       " '_you_',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaarrgghhhh',\n",
       " 'aaahhhh',\n",
       " 'aacvkc',\n",
       " 'aafreenet',\n",
       " 'aah',\n",
       " 'aakepler',\n",
       " 'aaldoubocopper',\n",
       " 'aalmchgur',\n",
       " 'aamir',\n",
       " 'aap',\n",
       " 'aarhus',\n",
       " 'aario',\n",
       " 'aaron',\n",
       " 'aaron_bratcherfpm',\n",
       " 'aarvik',\n",
       " 'aaspo',\n",
       " 'aau',\n",
       " 'aazaadee',\n",
       " 'ab',\n",
       " 'ababs',\n",
       " 'abandon',\n",
       " 'abandonded',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abbie',\n",
       " 'abbott',\n",
       " 'abbottpriory',\n",
       " 'abbotttps',\n",
       " 'abbreviations',\n",
       " 'abc',\n",
       " 'abd',\n",
       " 'abdel',\n",
       " 'abdi',\n",
       " 'abdication',\n",
       " 'abdo',\n",
       " 'abdomen',\n",
       " 'abdomens',\n",
       " 'abduct',\n",
       " 'abduction',\n",
       " 'abdul',\n",
       " 'abdulcebbar',\n",
       " 'abdulhamid',\n",
       " 'abdullah',\n",
       " 'abdullahad',\n",
       " 'abeaaz',\n",
       " 'abed',\n",
       " 'aber',\n",
       " 'aberdeen',\n",
       " 'aberration',\n",
       " 'abfb',\n",
       " 'abfreenet',\n",
       " 'abgarovich',\n",
       " 'abhor',\n",
       " 'abide',\n",
       " 'abides',\n",
       " 'abiding',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abkhazia',\n",
       " 'able',\n",
       " 'ablility',\n",
       " 'abnormal',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolishment',\n",
       " 'abominable',\n",
       " 'abominations',\n",
       " 'aboove',\n",
       " 'abort',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'aborts',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'about',\n",
       " 'abouts',\n",
       " 'above',\n",
       " 'above_',\n",
       " 'abraham',\n",
       " 'abramyan',\n",
       " 'abrasive',\n",
       " 'abravomondrian',\n",
       " 'abridged',\n",
       " 'abridgment',\n",
       " 'abroad',\n",
       " 'abrogate',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutes',\n",
       " 'absolutey',\n",
       " 'absolutist',\n",
       " 'absolve',\n",
       " 'absood',\n",
       " 'absorb',\n",
       " 'absorber',\n",
       " 'abstaining',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'absurb',\n",
       " 'absurd',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdum',\n",
       " 'abt',\n",
       " 'abu',\n",
       " 'abulfaz',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abuses',\n",
       " 'abusive',\n",
       " 'abyss',\n",
       " 'abzvirginia',\n",
       " 'ac',\n",
       " 'acad',\n",
       " 'academiae',\n",
       " 'academic',\n",
       " 'academica',\n",
       " 'academician',\n",
       " 'academy',\n",
       " 'acc',\n",
       " 'accede',\n",
       " 'accel',\n",
       " 'accelaration',\n",
       " 'accelarator',\n",
       " 'accelaratores',\n",
       " 'accelartor',\n",
       " 'acceleartion',\n",
       " 'acceler',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerates',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'accellerated',\n",
       " 'accelleration',\n",
       " 'accellerator',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accept',\n",
       " 'acceptab',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'acces',\n",
       " 'access',\n",
       " 'accessable',\n",
       " 'accessed',\n",
       " 'accesses',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'accommodate',\n",
       " 'accomodating',\n",
       " 'accompanied',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplis',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accorded',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accounting',\n",
       " 'accountplearn',\n",
       " 'accounts',\n",
       " 'accounts_',\n",
       " 'accross',\n",
       " 'accruing',\n",
       " 'accucolor',\n",
       " 'accummulate',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulating',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accusative',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accussations',\n",
       " 'accustomed',\n",
       " 'acd',\n",
       " 'acelerators',\n",
       " 'acem',\n",
       " 'acheived',\n",
       " 'acheiving',\n",
       " 'achevia',\n",
       " 'achieva',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achille',\n",
       " 'achim',\n",
       " 'achtung',\n",
       " 'acid',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'aclimated',\n",
       " 'aclimation',\n",
       " 'acm',\n",
       " 'acme',\n",
       " 'acmpsuvm',\n",
       " 'acns',\n",
       " 'aconstellation',\n",
       " 'acoopermac',\n",
       " 'acoopermacalstr',\n",
       " 'acording',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquisition',\n",
       " 'acrobatics',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'acs',\n",
       " 'acsu',\n",
       " 'act',\n",
       " 'actaully',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'acto',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actrix',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actualization',\n",
       " 'actually',\n",
       " 'actuated',\n",
       " 'actuator',\n",
       " 'acura',\n",
       " 'acutally',\n",
       " 'acutely',\n",
       " 'acz',\n",
       " 'ad',\n",
       " 'adaber',\n",
       " 'adagio',\n",
       " 'adalet',\n",
       " 'adam',\n",
       " 'adamdas',\n",
       " 'adamendor',\n",
       " 'adamian',\n",
       " 'adamof',\n",
       " 'adams',\n",
       " 'adamsbellini',\n",
       " 'adamsjgtewd',\n",
       " 'adamsrobotics',\n",
       " 'adamsupse',\n",
       " 'adana',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adapting',\n",
       " 'adaptive',\n",
       " 'adaptor',\n",
       " 'adaptors',\n",
       " 'adaptort',\n",
       " 'adb',\n",
       " 'adbs',\n",
       " 'adc',\n",
       " 'add',\n",
       " 'adda',\n",
       " 'addcs',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'additinol',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additive',\n",
       " 'additives',\n",
       " 'addons',\n",
       " 'address',\n",
       " 'addressable',\n",
       " 'addressapplelink',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adec',\n",
       " 'adelaide',\n",
       " 'aden',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adequete',\n",
       " 'adherence',\n",
       " 'adherents',\n",
       " 'adhesion',\n",
       " 'adjacent',\n",
       " 'adjective',\n",
       " 'adjoining',\n",
       " 'adjuration',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjutant',\n",
       " 'adl',\n",
       " 'adm',\n",
       " 'admd',\n",
       " 'admicj',\n",
       " 'admin',\n",
       " 'adminis',\n",
       " 'administer',\n",
       " 'administers',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'admins',\n",
       " 'adminstration',\n",
       " 'admire',\n",
       " 'admires',\n",
       " 'admission',\n",
       " 'admist',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admonition',\n",
       " 'adn',\n",
       " 'adnritvax',\n",
       " 'adobe',\n",
       " 'adolescents',\n",
       " 'adolf',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adopts',\n",
       " 'adoquince',\n",
       " 'ador',\n",
       " 'adrenaline',\n",
       " 'adrenalizing',\n",
       " 'adress',\n",
       " 'adressed',\n",
       " 'adressing',\n",
       " 'adrian',\n",
       " 'ads',\n",
       " 'adsdesign',\n",
       " 'adsorbent',\n",
       " 'adsorption',\n",
       " 'adult',\n",
       " 'adultary',\n",
       " 'adulteries',\n",
       " 'adultery',\n",
       " 'adultress',\n",
       " 'adultry',\n",
       " 'adults',\n",
       " 'aduz',\n",
       " 'advacne',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advancements',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'advantate',\n",
       " 'adventure',\n",
       " 'adventurer',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'ae',\n",
       " 'aeacebdialin',\n",
       " 'aeafb',\n",
       " 'aeceebdialin',\n",
       " 'aecfb',\n",
       " 'aedffeb',\n",
       " 'aeedialup',\n",
       " 'aefreenet',\n",
       " 'aegean',\n",
       " 'aegis',\n",
       " 'aem',\n",
       " 'aennig',\n",
       " 'aeons',\n",
       " 'aepworld',\n",
       " 'aero',\n",
       " 'aerodynamics',\n",
       " 'aeronautical',\n",
       " 'aeroplan',\n",
       " 'aerospace',\n",
       " 'aerostar',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'af',\n",
       " 'afabedkimball',\n",
       " 'afaeffedkimball',\n",
       " 'afair',\n",
       " 'afairs',\n",
       " 'afbceksg',\n",
       " 'afbewho',\n",
       " 'afbfeb',\n",
       " 'afc',\n",
       " 'afcefbbmeridian',\n",
       " 'afcfdfeb',\n",
       " 'afebefeb',\n",
       " 'afeccafb',\n",
       " 'afecdepyd',\n",
       " 'afedkimball',\n",
       " 'affafcb',\n",
       " 'affair',\n",
       " 'affaires',\n",
       " 'affairs',\n",
       " 'affcfcazelenetz',\n",
       " 'affeb',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affectionados',\n",
       " 'affectionate',\n",
       " 'affects',\n",
       " 'affedin',\n",
       " 'affeplanet',\n",
       " 'affiars',\n",
       " 'afficionado',\n",
       " 'affidavit',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affinity',\n",
       " 'affinty',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affirmatively',\n",
       " 'affirmed',\n",
       " 'affirming',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affording',\n",
       " 'affords',\n",
       " 'afghanistan',\n",
       " 'afghans',\n",
       " 'afifi',\n",
       " 'afishsvohmryleeandrew',\n",
       " 'afit',\n",
       " 'afix',\n",
       " 'afnews',\n",
       " 'aforementioned',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afro',\n",
       " 'afs',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'aftermarket',\n",
       " 'afternoon',\n",
       " 'aftersleep',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'afterwhich',\n",
       " 'aftwer',\n",
       " 'afu',\n",
       " 'afula',\n",
       " 'afungathena',\n",
       " 'ag',\n",
       " 'agabekian',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agaist',\n",
       " 'agar',\n",
       " 'agate',\n",
       " 'agayev',\n",
       " 'agdam',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ager',\n",
       " 'ages',\n",
       " 'agg',\n",
       " 'aggies',\n",
       " 'aggravated',\n",
       " 'aggresion',\n",
       " 'aggresively',\n",
       " 'aggression',\n",
       " 'aggressions',\n",
       " 'aggressive',\n",
       " 'aggressor',\n",
       " 'aggressors',\n",
       " 'aghdam',\n",
       " 'agian',\n",
       " 'aging',\n",
       " 'agip',\n",
       " 'agissements',\n",
       " 'agitating',\n",
       " 'agitators',\n",
       " 'agm',\n",
       " 'agnostic',\n",
       " 'agnosticism',\n",
       " 'agnostics',\n",
       " 'ago',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agression',\n",
       " 'agressive',\n",
       " 'agressively',\n",
       " 'agressiveness',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'agrinoenkidu',\n",
       " 'agron',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahalinin',\n",
       " 'aharonian',\n",
       " 'ahconstellation',\n",
       " 'ahdshaking',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahi',\n",
       " 'ahmad',\n",
       " 'ahmed',\n",
       " 'ahmedaceleborn',\n",
       " 'ahmedaice',\n",
       " 'ahmedamcrcim',\n",
       " 'ahmet',\n",
       " 'ahmeteecg',\n",
       " 'ahonen',\n",
       " 'ahyfn',\n",
       " 'ai',\n",
       " 'aicra',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aiff',\n",
       " 'aiken',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aimla',\n",
       " 'aims',\n",
       " 'aing',\n",
       " 'aint',\n",
       " 'aiquad',\n",
       " 'air',\n",
       " 'airbag',\n",
       " 'airbags',\n",
       " 'airbao',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'airfield',\n",
       " 'airforce',\n",
       " 'airlift',\n",
       " 'airlifts',\n",
       " 'airline',\n",
       " 'airliner',\n",
       " 'airliners',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airspace',\n",
       " 'airstrikes',\n",
       " 'airwolf',\n",
       " 'ais',\n",
       " 'aiu',\n",
       " 'aiva',\n",
       " 'aix',\n",
       " 'aiyfn',\n",
       " 'aj',\n",
       " 'ajami',\n",
       " 'ajar',\n",
       " 'ajerk',\n",
       " 'ajgritvax',\n",
       " 'ajjdove',\n",
       " 'ajrbigbird',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akademik',\n",
       " 'akarli',\n",
       " 'akbar',\n",
       " 'akboy',\n",
       " 'akcesser',\n",
       " 'akel',\n",
       " 'akgun',\n",
       " 'akhalkalak',\n",
       " 'akhalkalaki',\n",
       " 'akhiani',\n",
       " 'akhianiricks',\n",
       " 'akhtamar',\n",
       " 'akhuryan',\n",
       " 'akin',\n",
       " 'akins',\n",
       " 'akkus',\n",
       " 'akman',\n",
       " 'aknetcom',\n",
       " 'akron',\n",
       " 'aksin',\n",
       " 'aktif',\n",
       " 'akyfn',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alaa',\n",
       " 'alaapeewee',\n",
       " 'alabama',\n",
       " 'alaca',\n",
       " 'alah',\n",
       " 'alaikum',\n",
       " 'alain',\n",
       " 'alalim',\n",
       " 'alamo',\n",
       " 'alamos',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'alasini',\n",
       " 'alaska',\n",
       " 'alaylariyla',\n",
       " 'alban',\n",
       " 'albania',\n",
       " 'albany',\n",
       " 'albatross',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertolizei',\n",
       " 'albion',\n",
       " 'album',\n",
       " 'albuquerque',\n",
       " 'alcohlo',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcor',\n",
       " 'alders',\n",
       " 'aldus',\n",
       " 'ale',\n",
       " 'alehtori',\n",
       " 'aleksandr',\n",
       " 'aleksandrovich',\n",
       " 'aleppo',\n",
       " 'alert',\n",
       " 'alerts',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandria',\n",
       " 'alfa',\n",
       " 'alfalfa',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'algae',\n",
       " 'algebraic',\n",
       " 'algemeen',\n",
       " 'algeria',\n",
       " 'algerian',\n",
       " 'algonquin',\n",
       " 'alhafez',\n",
       " 'alhucsbuxa',\n",
       " 'ali',\n",
       " 'alian',\n",
       " 'alias',\n",
       " 'aliases',\n",
       " 'aliasing',\n",
       " 'alibi',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'aliev',\n",
       " 'alif',\n",
       " 'align',\n",
       " 'aligning',\n",
       " 'alignment',\n",
       " 'aligns',\n",
       " 'alik',\n",
       " 'alike',\n",
       " 'alink',\n",
       " 'aliquots',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'aliyah',\n",
       " 'aliye',\n",
       " 'all',\n",
       " 'alladin',\n",
       " 'allah',\n",
       " 'allakhverdiyev',\n",
       " 'allan',\n",
       " 'allatini',\n",
       " 'alle',\n",
       " 'allegations',\n",
       " 'allege',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'alleges',\n",
       " 'allegheny',\n",
       " 'alleging',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'allergy',\n",
       " 'allerton',\n",
       " 'alleviate',\n",
       " 'alleviated',\n",
       " 'alley',\n",
       " 'alleys',\n",
       " 'allgemeine',\n",
       " 'alliance',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'allocated',\n",
       " 'allocations',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allstate',\n",
       " 'allums',\n",
       " 'ally',\n",
       " 'alman',\n",
       " 'almanac',\n",
       " 'almanbsr',\n",
       " 'almighty',\n",
       " 'almodovar',\n",
       " 'almost',\n",
       " 'alms',\n",
       " 'alo',\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(vec,y_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "\n",
    "\n",
    "for b,c in zip(A,y_label):\n",
    "    if b ==c :\n",
    "        acc +1 \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "(acc/len(y_label))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism', 'comp.sys.mac.hardware', 'rec.autos', 'talk.politics.mideast'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_label[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(decision_function_shape=&#x27;ovo&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(decision_function_shape=&#x27;ovo&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(decision_function_shape='ovo')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc_classifier = svm.SVC(decision_function_shape='ovo')\n",
    "svc_classifier.fit(vec,y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7532, 78590)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/Desktop/Dissertation/implementations/Disso-COLD/proj_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 78590 features, but SVC is expecting 105178 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/max/Desktop/Dissertation/implementations/Disso-COLD/First_test.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/max/Desktop/Dissertation/implementations/Disso-COLD/First_test.ipynb#ch0000017?line=0'>1</a>\u001b[0m test_vec,test_features \u001b[39m=\u001b[39m extract_features(X_test_newsgroup_text)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/max/Desktop/Dissertation/implementations/Disso-COLD/First_test.ipynb#ch0000017?line=1'>2</a>\u001b[0m svc_classifier\u001b[39m.\u001b[39;49mpredict(test_vec)\n",
      "File \u001b[0;32m~/Desktop/Dissertation/implementations/Disso-COLD/proj_env/lib/python3.8/site-packages/sklearn/svm/_base.py:810\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    808\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    809\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m    811\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/Desktop/Dissertation/implementations/Disso-COLD/proj_env/lib/python3.8/site-packages/sklearn/svm/_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    418\u001b[0m     \u001b[39m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[39m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_for_predict(X)\n\u001b[1;32m    434\u001b[0m     predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[1;32m    435\u001b[0m     \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/Desktop/Dissertation/implementations/Disso-COLD/proj_env/lib/python3.8/site-packages/sklearn/svm/_base.py:611\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    608\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[0;32m--> 611\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    612\u001b[0m         X,\n\u001b[1;32m    613\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    614\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    615\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    616\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    617\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[1;32m    621\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/Desktop/Dissertation/implementations/Disso-COLD/proj_env/lib/python3.8/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/Dissertation/implementations/Disso-COLD/proj_env/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 78590 features, but SVC is expecting 105178 features as input."
     ]
    }
   ],
   "source": [
    "test_vec,test_features = extract_features(X_test_newsgroup_text)\n",
    "svc_classifier.predict(test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('proj_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00fa038ed48c4eea42567d095517abf695de8aa7e1762e670247e78bfd9e4117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
